{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cz_vyGrfHO6r",
        "outputId": "3522540e-5391-4f65-a07f-7c077b3d4ccf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n",
            "Requirement already satisfied: flash_attn in /usr/local/lib/python3.10/dist-packages (2.5.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash_attn) (2.1.0+cu121)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash_attn) (0.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from flash_attn) (23.2)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from flash_attn) (1.11.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash_attn) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash_attn) (1.3.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement transtormers (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for transtormers\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.37.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.26.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.7.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.1.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.37.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.26.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.15.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.42.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->bitsandbytes) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "# !huggingface-cli login --token  \n",
        "!pip install datasets > -\n",
        "!pip install rouge_score > -\n",
        "!pip install flash_attn\n",
        "!pip install transtormers\n",
        "!pip install --upgrade transformers\n",
        "!pip install accelerate\n",
        "!pip install peft\n",
        "!pip install bitsandbytes\n",
        "!pip install -qqq trl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d83LGrDp__MC",
        "outputId": "5cb0c2c7-22dc-43f3-ba5e-844dd2c3e9d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [1 InRelease 3,626 B/3,626 B 100%] [Connecting to ppa\u001b[0m\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcontent.net (185.125.190.\u001b[0m\r                                                                                                    \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcontent.net (185.125.190.\u001b[0m\r                                                                                                    \rGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\u001b[33m\r0% [Waiting for headers] [3 InRelease 12.7 kB/110 kB 12%] [Connecting to ppa.launchpadcontent.net (1\u001b[0m\r                                                                                                    \rHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,390 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,671 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,676 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,059 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,713 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,325 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:17 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,264 kB]\n",
            "Get:18 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,162 kB]\n",
            "Fetched 12.5 MB in 2s (5,195 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "34 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.10).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "! apt update && apt install git -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275,
          "referenced_widgets": [
            "82e2fdf3b5ef4ff29276b882ead4a75b",
            "7ed5ac7fd71f4d588088d958a63827b5",
            "6f17eedb783b4392b5be4af324c31379",
            "f926e0dd98c4404db64021bbf52dd67f",
            "51d10823c0ca44ea9b424c0ad8fed485",
            "df3026b628984fc5bcc98e7ad7a1b9d4",
            "0f3b512770404e8ebaea1c0dfabfe97e",
            "8ae9c3f114924a83afa423eabd1e3f2b",
            "07b2aed4f9034760851bbcd699e30e39",
            "28856addacad4b34beff81ad14560dde",
            "b88e2c0a2b704810a6411858d52d93a3",
            "2016e77e3d26446c9b29e7fae5c21643",
            "1859c453b8fa4d258e370c229ab42df0",
            "842ca16eabfb4f8f82ed858bdd180381",
            "99cc5928973544a0a6ff625a880921f0",
            "435056c5511341cba31fcc7ba3f4c24d",
            "213a0071f7cd4c309a04e2da274b538d",
            "7fdcae25c0084c73b4fb68300eed185d",
            "22b471f3eb694c50a59ba2a3c2b8ee26",
            "cd15db6a174a477cb3dd3707236f57bd",
            "33fa754a7f9c43fab6334f0042bd876a",
            "8b2a047d7d304ee09ecd10f95787acf0"
          ]
        },
        "id": "oDha0-JXHZFl",
        "outputId": "c650de37-e85a-4728-c6e9-8eb66eda91ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1429: FutureWarning: The repository for Salesforce/dialogstudio contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/Salesforce/dialogstudio\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82e2fdf3b5ef4ff29276b882ead4a75b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/18.3k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2016e77e3d26446c9b29e7fae5c21643",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/6.73k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import Dataset, load_dataset\n",
        "dataset = load_dataset(\"Salesforce/dialogstudio\", \"TweetSumm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qgse2hbBHdcI"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def generate_prompt(conversation: str) -> str:\n",
        "    return f\"\"\"### Instruction:\\nBelow is a conversation between a human and an agent. Write a summary of the conversation.\n",
        "\n",
        "### Input:\n",
        "{conversation.strip()}\n",
        "\"\"\".strip()\n",
        "\n",
        "def cleaning(text):\n",
        "\n",
        "    text = re.sub(r\"@[^\\s]+\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "\n",
        "    return re.sub(r\"\\^[^ ]+\", \"\", text)\n",
        "\n",
        "\n",
        "def conversation_extraction(data_point):\n",
        "    text = \"\"\n",
        "    for item in data_point[\"log\"]:\n",
        "        customer = cleaning(item[\"user utterance\"])\n",
        "        text += f\"Customer: {customer.strip()}\\n\"\n",
        "\n",
        "        agent = cleaning(item[\"system response\"])\n",
        "        text += f\"Agent: {agent.strip()}\\n\"\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "\n",
        "def redesign_data(data_point):\n",
        "    summaries = json.loads(data_point[\"original dialog info\"])[\"summaries\"][\n",
        "        \"abstractive_summaries\"\n",
        "    ]\n",
        "    summary = summaries[0]\n",
        "    summary = \" \".join(summary)\n",
        "\n",
        "    conversation_text = conversation_extraction(data_point)\n",
        "    text = \"### Instruction:\\nBelow is a conversation between a human and an agent. Write a summary of the conversation.\\n\\n### Input:\\n\" + conversation_text +  \"\\n\\n### Output:\\n\" + summary\n",
        "\n",
        "    return {\n",
        "        \"conversation\": conversation_text,\n",
        "        \"summary\": summary,\n",
        "        \"text\": text,\n",
        "        \"prompt\": generate_prompt(conversation_text),\n",
        "    }\n",
        "\n",
        "\n",
        "def preprocess_dataset(data: Dataset):\n",
        "    return (\n",
        "        data.shuffle(seed=42)\n",
        "        .map(redesign_data)\n",
        "        .remove_columns(\n",
        "            [\n",
        "                \"original dialog id\",\"new dialog id\",\"dialog index\",\n",
        "                \"original dialog info\",\"log\",\"prompt\",\n",
        "            ]\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpqvqEKCBoK-"
      },
      "outputs": [],
      "source": [
        "dataset[\"train\"] = preprocess_dataset(dataset[\"train\"])\n",
        "dataset[\"validation\"] = preprocess_dataset(dataset[\"validation\"])\n",
        "dataset[\"test\"] = preprocess_dataset(dataset[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VV49WzMbBrVU",
        "outputId": "386c53b9-d122-487d-83f9-3725af7e8c82"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-f3aa68319492>:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  rouge = load_metric('rouge')\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:752: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/rouge/rouge.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_metric\n",
        "from tqdm import tqdm\n",
        "rouge = load_metric('rouge')\n",
        "example_indices = [109]\n",
        "line = \"---------------------------------------------------------------------------------------------------\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge5Y-xM468Yz",
        "outputId": "1983d3a8-0431-4384-b44f-2cffdc7eff0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is a conversation between a human and an AI agent. With a summary of the conversation.\n",
            "### Input:\n",
            "Customer: On went to buy a Lip na mpesa wrist band in your shop in Thika and was sent to Annas Mall where i dint find your Team!\n",
            "Agent: Apologies for this, check with any M-PESA Agent, or Safaricom authorized dealer. You may also go back to our shop in Thika -(contd)to verify whether we have restocked.\n",
            "Customer: I was at your shop at Thika and they told me they were not sure where the guys dealing with the wrist bands were\n",
            "Agent: The mpesa 1 tap is not available at Thika its being piloted in Nairobi, Mombasa, Kisumu, Eldoret and Nyeri towns ... cont... currently. To get it you may visit the nearest town which is Nairobi to purchase one at a cost of 20/-.\n",
            "Customer: Would you please confirm for me if I will get the wrist band at your shop in Moi Avenue today so I don't have to travel for nothing.\n",
            "Agent: Hi, yes you will and at the moment it can only be used in the towns mentioned in our previous response only.\n",
            "Customer: On Tuesday I went to your shop on Moi Avenue to get wrist band but was told they ended,but was told I would be informed when they are ready Cont...Are they still not ready yet? ?\n",
            "Agent: Hi, you can visit any authorized dealer or the other shops in town for one.\n",
            "\n",
            "### Output:\n",
            "Customer wants the wrist band which was not available in the stop so customer says to confirm if the wrist band is present. Agent says to visit any authorized dealer or shop in town for one.\n",
            "\n",
            "Below is a conversation between a human and an AI agent. Write a summary of the conversation.\n",
            "### Input:\n",
            "Customer: if you have a commercial that says you have 100mbs for 44.99 honor it in all your markets you provide 100mbs at.\n",
            "Agent: Good morning. In some areas of our markets our network is not yet able to provide those speeds. We do not offer a...\n",
            "Customer: My area offered me 100mb for more money so now that this is the standard and they do offer 100mb shouldnâ€™t I receive it right away\n",
            "Agent: I would be happy to take a look. If you upgraded to the 100 plan and are not receiving this we can investigate. H...\n",
            "Customer: I have the 60mb plan but I watch many commercials saying they offer 100mb for the same price. My area has 100mb so shouldnâ€™t I be getting it\n",
            "Agent: I am sorry, the advertisements are package/product prices for new customers. If you would like to upgrade that sh...\n",
            "Customer: So you leave existing customers below your new standards is what your telling me, right?\n",
            "Agent: Hi William, In order to discuss this further we ask that you please contact our billing specialist at: 800-892-4357â€‹â€‹. Thank you.\n",
            "\n",
            "### Output:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def make_prompt(examples, sample):\n",
        "    prompt = ''\n",
        "    for index in examples:\n",
        "        conversation = dataset['test'][index]['conversation']\n",
        "        summary = dataset['test'][index]['summary']\n",
        "        prompt += f\"\"\"Below is a conversation between a human and an AI agent. With a summary of the conversation.\n",
        "### Input:\n",
        "{conversation}\n",
        "### Output:\n",
        "{summary}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    conversation = dataset['test'][sample]['conversation']\n",
        "\n",
        "    prompt += f\"\"\"Below is a conversation between a human and an AI agent. Write a summary of the conversation.\n",
        "### Input:\n",
        "{conversation}\n",
        "### Output:\n",
        "\"\"\"\n",
        "    return prompt\n",
        "prompt = print(make_prompt([30], 109))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yQnQAtcQ7AVM"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        ")\n",
        "from peft import LoraConfig, PeftModel, get_peft_model, TaskType\n",
        "from trl import SFTTrainer\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRFI9i-fAQLf",
        "outputId": "8d1fdf87-f802-44b7-b7ff-aebabf65eec1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"stabilityai/stablelm-3b-4e1t\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"stabilityai/stablelm-3b-4e1t\",\n",
        "    use_safetensors=True,\n",
        "    quantization_config=bnb_config,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FUVuq_adj7d5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate model size\n",
        "def calculate_model_size(model):\n",
        "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "    return params / (1024 ** 2)  # Convert to megabytes\n",
        "\n",
        "\n",
        "model_size_after_quantization = calculate_model_size(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLicsgBPkgIn",
        "outputId": "eca96105-b3e4-45b0-86e8-ae3d56630f66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "245.9423828125"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_size_after_quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GP0abQurkVTF"
      },
      "outputs": [],
      "source": [
        "model2 = AutoModelForCausalLM.from_pretrained(\"stabilityai/stablelm-3b-4e1t\", trust_remote_code=True,torch_dtype=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bCy8Ni_kmJM",
        "outputId": "5b1c2c9d-56b7-4731-fa50-6cb45789415c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model size before quantization: 2665.9423828125 MB\n",
            "Model size after quantization: 245.9423828125 MB\n",
            "Model size reduction after quantization: 2420.0 MB\n"
          ]
        }
      ],
      "source": [
        "model_size_before_quantization = calculate_model_size(model2)\n",
        "model_size_reduction = model_size_before_quantization - model_size_after_quantization\n",
        "\n",
        "print(f\"Model size before quantization: {model_size_before_quantization} MB\")\n",
        "print(f\"Model size after quantization: {model_size_after_quantization} MB\")\n",
        "print(f\"Model size reduction after quantization: {model_size_reduction} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atTWLhzO7FiN",
        "outputId": "26edd99c-eae0-4dbc-d3e3-55ff7d60145f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 20,971,520 || all params: 2,816,414,720 || trainable%: 0.7446176108609459\n"
          ]
        }
      ],
      "source": [
        "peft_config = LoraConfig(\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    r=32,\n",
        "    lora_alpha=8,\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\"\n",
        "    ],\n",
        "    bias=\"none\"\n",
        ")\n",
        "\n",
        "model.config.use_cache = False\n",
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFm0J7ix7HUN"
      },
      "outputs": [],
      "source": [
        "training_arguments = TrainingArguments(\n",
        "    output_dir=\"lora-r32-finetuned\",\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    learning_rate=1e-4,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    save_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_steps=1,\n",
        "    num_train_epochs=5,\n",
        "    push_to_hub=False\n",
        ")\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validation\"],\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length= 4096,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePOatHDs_DGl",
        "outputId": "3842922e-377d-4b2b-d6dd-f8f7232952c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 20,971,520 || all params: 2,816,414,720 || trainable%: 0.7446176108609459\n"
          ]
        }
      ],
      "source": [
        "trainer.model.print_trainable_parameters()\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "iJNoAipt97AS",
        "outputId": "1d516738-d24a-4f35-c1fe-711fea1e85cf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4395' max='4395' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4395/4395 35:46, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.677700</td>\n",
              "      <td>2.075731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.935600</td>\n",
              "      <td>2.058427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.299700</td>\n",
              "      <td>2.063561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.845900</td>\n",
              "      <td>2.091055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.658000</td>\n",
              "      <td>2.105810</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4395, training_loss=1.9214049900486743, metrics={'train_runtime': 2150.5955, 'train_samples_per_second': 2.044, 'train_steps_per_second': 2.044, 'total_flos': 2.28768123250176e+16, 'train_loss': 1.9214049900486743, 'epoch': 5.0})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGgWDL927SE9"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "  \"stabilityai/stablelm-3b-4e1t\",\n",
        "  trust_remote_code=True,\n",
        "  torch_dtype=\"auto\",\n",
        "  use_safetensors=True,\n",
        ").to(\"cuda\")\n",
        "peft_model = PeftModel.from_pretrained(model, \"lora-r32-finetuned/checkpoint-4395\", from_transformers=True)\n",
        "model = peft_model.merge_and_unload()\n",
        "\n",
        "model.config.pad_token_id = tokenizer.eos_token_id\n",
        "model.config.eos_token_id = tokenizer.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tmfh30v7LZ1",
        "outputId": "8e07e68e-cad6-46f9-9dc0-a78ebf298199"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 110/110 [11:19<00:00,  6.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "average score one shot:{'rouge1': 0.3681059483218816, 'rouge2': 0.13981877957788952, 'rougeL': 0.2953305409730834, 'rougeLsum': 0.30379438020703853}\n",
            "average score zero shot:{'rouge1': 0.4332597143242216, 'rouge2': 0.25816331149057714, 'rougeL': 0.3617806393058581, 'rougeLsum': 0.3747735275398468}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "results_zero_shot = []\n",
        "results_one_shot = []\n",
        "for index in tqdm(range(110)):\n",
        "    model.config.pad_token_id = tokenizer.eos_token_id\n",
        "    summary = dataset['test'][index]['summary']\n",
        "    if 109 > index:\n",
        "      prompt = make_prompt([index+1], index)\n",
        "    else:\n",
        "      prompt = make_prompt([30], index)\n",
        "    inputs = tokenizer(prompt, return_tensors='pt').to(\"cuda\")\n",
        "    token = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=64,\n",
        "        temperature=0.75,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        top_p=0.95,\n",
        "        do_sample=True,\n",
        "        )\n",
        "    completion_tokens = token[0][inputs['input_ids'].size(1):]\n",
        "    completion = tokenizer.decode(completion_tokens, skip_special_tokens=True)\n",
        "    results_one_shot.append(rouge.compute(predictions=[completion], references=[summary]))\n",
        "    prompt = dataset['test'][index]['text']\n",
        "    inputs = tokenizer(prompt, return_tensors='pt').to(\"cuda\")\n",
        "    token = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=64,\n",
        "        temperature=0.75,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        top_p=0.95,\n",
        "        do_sample=True,\n",
        "        )\n",
        "    completion_tokens = token[0][inputs['input_ids'].size(1):]\n",
        "    completion = tokenizer.decode(completion_tokens, skip_special_tokens=True)\n",
        "    results_zero_shot.append(rouge.compute(predictions=[completion], references=[summary]))\n",
        "average_score_zero_shot = {metric: sum([result[metric].mid.fmeasure for result in results_zero_shot]) / len(results_zero_shot)\n",
        "                  for metric in results_zero_shot[0]}\n",
        "average_score_one_shot = {metric: sum([result[metric].mid.fmeasure for result in results_one_shot]) / len(results_one_shot)\n",
        "                  for metric in results_one_shot[0]}\n",
        "print(f\"average score one shot:{average_score_one_shot}\\naverage score zero shot:{average_score_zero_shot}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnvIFvWn-shJ",
        "outputId": "2073381f-3675-4ef1-ca19-62b6a9dc7bec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): StableLMEpochForCausalLM(\n",
              "      (model): StableLMEpochModel(\n",
              "        (embed_tokens): Embedding(50304, 2560)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x DecoderLayer(\n",
              "            (self_attn): Attention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2560, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=2560, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2560, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=2560, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2560, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=2560, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2560, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=2560, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (rotary_emb): RotaryEmbedding()\n",
              "            )\n",
              "            (mlp): MLP(\n",
              "              (gate_proj): Linear4bit(in_features=2560, out_features=6912, bias=False)\n",
              "              (up_proj): Linear4bit(in_features=2560, out_features=6912, bias=False)\n",
              "              (down_proj): Linear4bit(in_features=6912, out_features=2560, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "            (post_attention_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=2560, out_features=50304, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABO2UtdHYea8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07b2aed4f9034760851bbcd699e30e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f3b512770404e8ebaea1c0dfabfe97e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1859c453b8fa4d258e370c229ab42df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_213a0071f7cd4c309a04e2da274b538d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7fdcae25c0084c73b4fb68300eed185d",
            "value": "Downloading readme: 100%"
          }
        },
        "2016e77e3d26446c9b29e7fae5c21643": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1859c453b8fa4d258e370c229ab42df0",
              "IPY_MODEL_842ca16eabfb4f8f82ed858bdd180381",
              "IPY_MODEL_99cc5928973544a0a6ff625a880921f0"
            ],
            "layout": "IPY_MODEL_435056c5511341cba31fcc7ba3f4c24d"
          }
        },
        "213a0071f7cd4c309a04e2da274b538d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22b471f3eb694c50a59ba2a3c2b8ee26": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28856addacad4b34beff81ad14560dde": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33fa754a7f9c43fab6334f0042bd876a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "435056c5511341cba31fcc7ba3f4c24d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51d10823c0ca44ea9b424c0ad8fed485": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f17eedb783b4392b5be4af324c31379": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ae9c3f114924a83afa423eabd1e3f2b",
            "max": 18289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07b2aed4f9034760851bbcd699e30e39",
            "value": 18289
          }
        },
        "7ed5ac7fd71f4d588088d958a63827b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df3026b628984fc5bcc98e7ad7a1b9d4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0f3b512770404e8ebaea1c0dfabfe97e",
            "value": "Downloading builder script: 100%"
          }
        },
        "7fdcae25c0084c73b4fb68300eed185d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82e2fdf3b5ef4ff29276b882ead4a75b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ed5ac7fd71f4d588088d958a63827b5",
              "IPY_MODEL_6f17eedb783b4392b5be4af324c31379",
              "IPY_MODEL_f926e0dd98c4404db64021bbf52dd67f"
            ],
            "layout": "IPY_MODEL_51d10823c0ca44ea9b424c0ad8fed485"
          }
        },
        "842ca16eabfb4f8f82ed858bdd180381": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22b471f3eb694c50a59ba2a3c2b8ee26",
            "max": 6727,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd15db6a174a477cb3dd3707236f57bd",
            "value": 6727
          }
        },
        "8ae9c3f114924a83afa423eabd1e3f2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b2a047d7d304ee09ecd10f95787acf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99cc5928973544a0a6ff625a880921f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33fa754a7f9c43fab6334f0042bd876a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8b2a047d7d304ee09ecd10f95787acf0",
            "value": " 6.73k/6.73k [00:00&lt;00:00, 373kB/s]"
          }
        },
        "b88e2c0a2b704810a6411858d52d93a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd15db6a174a477cb3dd3707236f57bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df3026b628984fc5bcc98e7ad7a1b9d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f926e0dd98c4404db64021bbf52dd67f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28856addacad4b34beff81ad14560dde",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b88e2c0a2b704810a6411858d52d93a3",
            "value": " 18.3k/18.3k [00:00&lt;00:00, 1.15MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
